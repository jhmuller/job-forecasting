{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Part10: Run Notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T06:51:17.881958Z",
     "start_time": "2020-11-24T06:51:16.914536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import touch\n",
    "import inspect\n",
    "import numpy\n",
    "import pandas as pd\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 3.9.2 of Python\n",
      "No __version__ for touch as touch\n",
      "version numpy of numpy as 1.20.1 \n",
      "version pd of pandas as 1.2.3 \n"
     ]
    }
   ],
   "source": [
    "mlist = list(filter(lambda x: inspect.ismodule(x[1]), locals().items()))\n",
    "vi = sys.version_info\n",
    "print(\"version {0}.{1}.{2} of Python\".format(vi.major, vi.minor, vi.micro))\n",
    "for name, mod in mlist:\n",
    "    mname = name\n",
    "    if name.startswith(\"__\"):\n",
    "        continue\n",
    "    if hasattr(mod, \"__version__\"):\n",
    "        mname = name\n",
    "        if hasattr(mod, \"__path__\"):\n",
    "            mname = os.path.split(mod.__path__[0])[1]\n",
    "        print(\"version {1} of {0} as {2} \".format(mname, name, mod.__version__))\n",
    "    elif hasattr(mod, \"__file__\") and \"site-packages\" in mod.__file__:\n",
    "        print(\"No __version__ for {0} as {1}\".format(mname, name))\n",
    "del mod\n",
    "del name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T06:51:39.513160Z",
     "start_time": "2020-11-24T06:51:39.333165Z"
    }
   },
   "outputs": [],
   "source": [
    "# to get the names of notebook files in a directory\n",
    "def get_project_notebooks():\n",
    "    from nbformat import read, NO_CONVERT\n",
    "    import os\n",
    "    import datetime\n",
    "    proj_nbs = []\n",
    "    nbs = [f for f in os.listdir() if f.endswith(\".ipynb\")]\n",
    "    part_nbs = [f for f in nbs if f.startswith(\"Part\")]\n",
    "    return(part_nbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T06:51:41.721852Z",
     "start_time": "2020-11-24T06:51:41.685659Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the source code for a cell\n",
    "def print_source(cell):\n",
    "    print(\"type cell= {0}\".format(type(cell)))\n",
    "    src = cell[\"source\"]\n",
    "    lines = src.split(\"\\n\")\n",
    "    print(\"{0} lines\".format(len(lines)))\n",
    "    for i,line in enumerate(lines):\n",
    "        print(\"({0}){1}\".format(i, line))\n",
    "\n",
    "# run notebook code\n",
    "def run_nb_code(nbfile):\n",
    "    from nbformat import read, NO_CONVERT\n",
    "    import os\n",
    "    import datetime\n",
    "    res = \"Start time: \" + str(datetime.datetime.now())\n",
    "    with open(nbfile) as fp:\n",
    "        notebook = read(fp, NO_CONVERT)\n",
    "    cells = notebook['cells']\n",
    "    code_cells = [c for c in cells if c['cell_type'] == 'code']\n",
    "    for i, cell in enumerate(code_cells):\n",
    "        src = cell['source']\n",
    "        #print(\"{0}<{1}>\".format(li, line))                \n",
    "        try:\n",
    "            exec(src, globals(), locals())\n",
    "        except Exception as e:\n",
    "            print(\"Error on cell {0}\\n\".format(i))\n",
    "            print(src)\n",
    "            print_source(cell)\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            import traceback\n",
    "            traceback.print_tb(exc_tb)\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "            return((exc_type, exc_obj, exc_tb, fname))\n",
    "    res += \"end: \" + str(datetime.datetime.now())\n",
    "    return res\n",
    "# run notebook code\n",
    "def get_first_cell_line(nbfile):\n",
    "    from nbformat import read, NO_CONVERT\n",
    "    import os\n",
    "    import datetime\n",
    "    res = \"Start time: \" + str(datetime.datetime.now())\n",
    "    with open(nbfile) as fp:\n",
    "        notebook = read(fp, NO_CONVERT)\n",
    "    cells = notebook['cells']\n",
    "    if not cells:\n",
    "        return \"\"\n",
    "    lines = cells[0][\"source\"].split(\"\\n\")\n",
    "    if not lines:\n",
    "        return \"\"\n",
    "    return lines[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T06:53:14.755733Z",
     "start_time": "2020-11-24T06:51:58.710791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Part_0_Setup.ipynb', 'Part_1_Intro_Overview.ipynb', 'Part_2_DataSources.ipynb', 'Part_3_Fred.ipynb', 'Part_4_Weekly_Claims.ipynb', 'Part_5_UMich_Sentiment.ipynb', 'Part_6_GoogleTrends.ipynb', 'Part_7_Plot_Claims.ipynb', 'Part_8_Combine_Datasets.ipynb']\n"
     ]
    }
   ],
   "source": [
    "def get_run_order(nb_names, verbosity=0):\n",
    "  tups = []\n",
    "  not_run = []\n",
    "  \n",
    "  for nb_name in nb_names:\n",
    "    if verbosity > 0:\n",
    "      print(nb_name)\n",
    "    name_parts = nb_name.split(\"_\")\n",
    "    if len(name_parts) < 2:\n",
    "      not_run.append((\"name doesn't start with 'Part'\", nb_name))\n",
    "      continue\n",
    "    elif name_parts[1] == \"99\":\n",
    "      not_run.append((\"runall\", nb_name))\n",
    "      continue\n",
    "    try:\n",
    "      id = int(name_parts[1])\n",
    "      tups.append((id, nb_name))\n",
    "    except:\n",
    "      not_run.append(\"can't convert {0} to int\".format(name_parts[1]), nb_name)\n",
    "  tups.sort()\n",
    "  to_run = [x[1] for x in tups]\n",
    "  return to_run, not_run\n",
    "  \n",
    "  \n",
    "nb_names = get_project_notebooks()\n",
    "\n",
    "to_run, not_run = get_run_order(nb_names, verbosity=0)\n",
    "print(to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T06:53:14.755733Z",
     "start_time": "2020-11-24T06:51:58.710791Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Part_0_Setup.ipynb  <2021-10-30 17:09:51.850805>\n",
      "  done  <Part_0_Setup.ipynb>\n",
      "Part_1_Intro_Overview.ipynb  <2021-10-30 17:09:51.853798>\n",
      "  done  <Part_1_Intro_Overview.ipynb>\n",
      "Part_2_DataSources.ipynb  <2021-10-30 17:09:51.855792>\n",
      "  done  <Part_2_DataSources.ipynb>\n",
      "Part_3_Fred.ipynb  <2021-10-30 17:09:51.857788>\n",
      "  done  <Part_3_Fred.ipynb>\n",
      "Part_4_Weekly_Claims.ipynb  <2021-10-30 17:10:16.681369>\n",
      "  done  <Part_4_Weekly_Claims.ipynb>\n",
      "Part_5_UMich_Sentiment.ipynb  <2021-10-30 17:10:24.374937>\n",
      "  done  <Part_5_UMich_Sentiment.ipynb>\n",
      "Part_6_GoogleTrends.ipynb  <2021-10-30 17:10:29.106942>\n",
      "  done  <Part_6_GoogleTrends.ipynb>\n",
      "Part_7_Plot_Claims.ipynb  <2021-10-30 17:11:04.999102>\n",
      "  done  <Part_7_Plot_Claims.ipynb>\n",
      "Part_8_Combine_Datasets.ipynb  <2021-10-30 17:11:05.519808>\n",
      "C:\\Users\\jmull\\Anaconda3\\envs\\payems\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82161.6006658698, tolerance: 46963.92433953488\n",
      "  done  <Part_8_Combine_Datasets.ipynb>\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr nb_out\n",
    "def extract_part(name):\n",
    "  parts = name.split(\"_\")\n",
    "  try:\n",
    "    part = int(parts[1])\n",
    "    return part\n",
    "  except:\n",
    "    exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "    fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "    print(exc_type, fname, exc_tb.tb_lineno)     \n",
    "    \n",
    "for nb_name in to_run:\n",
    "    part = extract_part(nb_name)\n",
    "    if part < 0:\n",
    "      continue\n",
    "    sys.stderr.write(\"{0}  <{1}>\\n\".format(nb_name, datetime.datetime.now()))\n",
    "    %run $nb_name\n",
    "    sys.stderr.write(\"  done  <{0}>\\n\".format(nb_name, datetime.datetime.now()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 3.9.2 of Python\n",
      "version 1.20.1 of numpy\n",
      "version 1.2.3 of pd\n",
      "version 1.20.1 of np\n",
      "version 3.3.4 of mpl\n",
      "0.4.2\n",
      "series: PAYEMS, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:53.431872\n",
      "rows= 177\n",
      "series: USPRIV, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:54.106134\n",
      "rows= 177\n",
      "series: NPPTTL, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:54.870854\n",
      "rows= 177\n",
      "series: ICSA, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:55.725819\n",
      "rows= 773\n",
      "series: CCSA, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:56.915727\n",
      "rows= 772\n",
      "series: JTS1000JOL, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:59.397657\n",
      "rows= 176\n",
      "series: JTS1000HIL, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:09:59.966503\n",
      "rows= 176\n",
      "series: JTS1000TSL, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:00.493307\n",
      "rows= 176\n",
      "series: CSCICP03USM665S, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:01.134941\n",
      "rows= 177\n",
      "series: BSCICP03USM665S, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:04.357562\n",
      "rows= 177\n",
      "series: UNRATE, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:07.765061\n",
      "rows= 177\n",
      "series: UNEMPLOY, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:08.104515\n",
      "rows= 177\n",
      "series: CLF16OV, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:08.530280\n",
      "rows= 177\n",
      "series: UEMP27OV, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:08.949764\n",
      "rows= 177\n",
      "series: U6Rate, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:09.347801\n",
      "rows= 177\n",
      "series: CIVPART, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:09.626271\n",
      "rows= 177\n",
      "series: LNS12032194, obs_start: 2007-01-01, obs_end: 2021-10-30\n",
      "get_series_all_releases <2021-10-30 17:10:09.878639\n",
      "rows= 177\n",
      "2021-10-30 17:10:10.267442\n",
      "2021-10-30 17:10:10.271431\n",
      "2021-10-30 17:10:16.681369\n",
      "['Unnamed: 6', 'Unnamed: 7']\n",
      "dropping columns ['Unnamed: 6', 'Unnamed: 7']\n",
      "weekly_pandemic_claims.xlsx\n",
      "all the data cols [['PUA IC', 'PUA CC', 'PEUC CC']] are numeric\n",
      "Plotting IC\n",
      "Plotting CC\n",
      "version 3.9.2 of Python\n",
      "version 1.20.1 of numpy\n",
      "version 1.2.3 of pd\n",
      "version 1.20.1 of np\n",
      "version 3.3.4 of mpl\n",
      "version 0.4.2 of fredapi\n",
      "version 2.2.1 of re\n",
      "version 2.25.1 of requests\n",
      "version 2.0.1 of xlrd\n",
      "version 3.141.0 of selenium\n",
      "version 3.14.1 of webdriver\n",
      "set()\n",
      "{'sca-table5-on-2021-Oct-30.csv'}\n",
      "new file: ./data/temp\\sca-table5-on-2021-Oct-30.csv\n",
      "Index(['Month', 'Year', 'Personal Finance Current',\n",
      "       'Personal Finance Expected', 'Business Condition 12 Months',\n",
      "       'Business Condition 5 Years', 'Buying Conditions', 'Current Index',\n",
      "       'Expected Index', 'Unnamed: 9'],\n",
      "      dtype='object')\n",
      "2021-10-30 17:10:29.106942\n",
      "version 3.9.2 of Python\n",
      "No __version__ for touch as touch\n",
      "version numpy of numpy as 1.20.1 \n",
      "version pd of pandas as 1.2.3 \n",
      "version np of numpy as 1.20.1 \n",
      "version mpl of matplotlib as 3.3.4 \n",
      "No __version__ for plt as plt\n",
      "version fredapi of fredapi as 0.4.2 \n",
      "version re of re as 2.2.1 \n",
      "version requests of requests as 2.25.1 \n",
      "version xlrd of xlrd as 2.0.1 \n",
      "version selenium of selenium as 3.141.0 \n",
      "version webdriver of webdriver as 3.14.1 \n",
      "version pn of plotnine as 0.7.1 \n",
      "No __version__ for pt as pt\n",
      "            work  isPartial\n",
      "date                       \n",
      "2021-06-12    46      False\n",
      "2021-06-13    55      False\n",
      "            work  isPartial\n",
      "date                       \n",
      "2021-10-27    95      False\n",
      "2021-10-28    89      False\n",
      "Start 2021-10-30 17:10:30.434631\n",
      "<kw#1='jobs''>, <kw#2='work''>, <kw#3='indeed jobs''>, <kw#4='jobs near me''>, <kw#5='work from home''>, <kw#6='indeed jobs near me''>, <kw#7='jobs near me hiring''>, <kw#8='jobs work from home''>, <kw#9='jobs hiring near me indeed''>, <kw#10='jobs hiring part time near me''>, <kw#11='work from home jobs amazon''>, <kw#12='places hiring near me''>, <kw#13='job hiring near me''>, <kw#14='work from home jobs near me''>, <kw#15='places hiring part time near me''>, <kw#16='jobs hiring near me''>, <kw#17='work from home amazon jobs near me''>, <kw#18='part time jobs near me''>, <kw#19='jobs near me part time hiring''>, <kw#20='hiring near me part time''>, <kw#21='jobs near me part time''>, Done 2021-10-30 17:10:54.314359\n",
      "Found 21 queries\n",
      "Index(['jobs near me part time', 'hiring near me part time',\n",
      "       'jobs near me part time hiring', 'part time jobs near me',\n",
      "       'work from home amazon jobs near me', 'jobs hiring near me',\n",
      "       'places hiring part time near me', 'work from home jobs near me',\n",
      "       'job hiring near me', 'places hiring near me',\n",
      "       'work from home jobs amazon', 'jobs work from home',\n",
      "       'jobs near me hiring', 'indeed jobs near me', 'work from home',\n",
      "       'jobs near me', 'indeed jobs', 'work', 'jobs hiring part time near me',\n",
      "       'jobs hiring near me indeed', 'jobs'],\n",
      "      dtype='object')\n",
      "(6, 4)\n",
      "(104, 22)\n",
      "            jobs near me part time  hiring near me part time  \\\n",
      "date                                                           \n",
      "2019-11-03                      81                        82   \n",
      "2019-11-10                      67                        59   \n",
      "\n",
      "            jobs near me part time hiring  part time jobs near me  \\\n",
      "date                                                                \n",
      "2019-11-03                             87                      81   \n",
      "2019-11-10                             50                      67   \n",
      "\n",
      "            work from home amazon jobs near me  jobs hiring near me  \\\n",
      "date                                                                  \n",
      "2019-11-03                                  40                   72   \n",
      "2019-11-10                                  27                   69   \n",
      "\n",
      "            places hiring part time near me  work from home jobs near me  \\\n",
      "date                                                                       \n",
      "2019-11-03                               27                           33   \n",
      "2019-11-10                               27                           42   \n",
      "\n",
      "            job hiring near me  places hiring near me  ...  \\\n",
      "date                                                   ...   \n",
      "2019-11-03                  83                     38  ...   \n",
      "2019-11-10                  74                     31  ...   \n",
      "\n",
      "            jobs near me hiring  indeed jobs near me  work from home  \\\n",
      "date                                                                   \n",
      "2019-11-03                   72                   64              37   \n",
      "2019-11-10                   69                   68              34   \n",
      "\n",
      "            jobs near me  indeed jobs  work  jobs hiring part time near me  \\\n",
      "date                                                                         \n",
      "2019-11-03            87           85    62                             87   \n",
      "2019-11-10            86           74    58                             50   \n",
      "\n",
      "            jobs hiring near me indeed  jobs  diff  \n",
      "date                                                \n",
      "2019-11-03                          47    80   NaN  \n",
      "2019-11-10                          58    74  -6.0  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "2021-10-30 17:11:04.995074\n",
      "2021-10-30 17:11:04.999102\n",
      "google_trends  shape:(104, 23)\n",
      "tidy_fred  shape:(926, 18)\n",
      "umich_exp  shape:(164, 5)\n",
      "us_pau_claims  shape:(82, 4)\n",
      "date                        object\n",
      "CCSA: Continued Claims     float64\n",
      "ICSA: Initial Claims       float64\n",
      "dtype: object\n",
      "date shape: (926,)\n",
      " done, <2021-10-30 17:11:05.091953>\n",
      "Index(['CCSA: Continued Claims ', 'ICSA: Initial Claims', 'PUA IC', 'PUA CC',\n",
      "       'PEUC CC'],\n",
      "      dtype='object')\n",
      "['google_trends.csv', 'tidy_fred.csv', 'umich_exp.csv', 'us_pau_claims.csv']\n",
      "google_trends.csv\n",
      "           date  jobs near me part time\n",
      "103  2021-10-24                      72\n",
      "2021-10-24\n",
      "tidy_fred.csv\n",
      "           date  PAYEMS:Total Nonfarm\n",
      "925  2021-10-23                   NaN\n",
      "2021-10-24\n",
      "umich_exp.csv\n",
      "           date  Personal Finance Expected\n",
      "163  2021-08-15                        111\n",
      "2021-10-24\n",
      "us_pau_claims.csv\n",
      "          date  PUA IC\n",
      "81  2021-10-23    2532\n",
      "2021-10-24\n",
      "129 7\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "(16, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nb_out.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "payems",
   "language": "python",
   "name": "payems"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
